{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Unconditional Samples (GPT-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Required Libraries\n",
    "!pip3 install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kit [00:00, 485kit/s]                                                      \n",
      "Fetching encoder.json: 1.04Mit [00:00, 19.7Mit/s]                                                   \n",
      "Fetching hparams.json: 1.00kit [00:00, 650kit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 66.2Mit/s]                                  \n",
      "Fetching model.ckpt.index: 6.00kit [00:00, 5.05Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 472kit [00:00, 12.9Mit/s]                                                 \n",
      "Fetching vocab.bpe: 457kit [00:00, 27.9Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "#Download the models\n",
    "#Model Options: 117M or 345M\n",
    "!python3 download_model.py 117M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model, sample, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(\n",
    "    model_name='117M',\n",
    "    seed=None,\n",
    "    nsamples=0,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "    models_dir='models',\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the sample_model\n",
    "    :model_name=117M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to\n",
    "     reproduce results\n",
    "    :nsamples=0 : Number of samples to return, if 0, continues to\n",
    "     generate samples indefinately.\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "     :models_dir : path to parent folder containing model subfolders\n",
    "     (i.e. contains the <model_name> folder)\n",
    "    \"\"\"\n",
    "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
    "    enc = encoder.get_encoder(model_name, models_dir)\n",
    "    hparams = model.default_hparams()\n",
    "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
    "        hparams.override_from_dict(json.load(f))\n",
    "\n",
    "    if length is None:\n",
    "        length = hparams.n_ctx\n",
    "    elif length > hparams.n_ctx:\n",
    "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
    "\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "\n",
    "        output = sample.sample_sequence(\n",
    "            hparams=hparams, length=length,\n",
    "            start_token=enc.encoder['<|endoftext|>'],\n",
    "            batch_size=batch_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )[:, 1:]\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "        generated = 0\n",
    "        while nsamples == 0 or generated < nsamples:\n",
    "            out = sess.run(output)\n",
    "            for i in range(batch_size):\n",
    "                generated += batch_size\n",
    "                text = enc.decode(out[i])\n",
    "                print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
    "                print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/gpt-2-notebook/sample.py:46: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /root/gpt-2-notebook/sample.py:48: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/117M/model.ckpt\n",
      "======================================== SAMPLE 1 ========================================\n",
      "Podcast\n",
      "\n",
      "Enough stated, we need to start talking about getting science research funding.\n",
      "\n",
      "In fall of this year, the National Science Foundation will stand to gain ample number of jobs and revenues when it comes to deeper amounts of academic science research.\n",
      "\n",
      "Fetish tells, \"Of the $500 billion in data sharing funding awarded annually, around $500 billion gets made each year under Title 1R.\" She claims MIT and rival UCLA – short for American Institute of Technology – were awarded about half of what NIST's Science News Challenge money is.\n",
      "\n",
      "Now GMB Partners and L'Amy Palingrilly are poised to get 32% and 29% of what NIST the Professor of Physical Science's research funding is \"penned,\" Canada's Institut de Recherche et de Recherches science Science Network (IPCR) claims post Space Telescope Particle Physics Award winning Pascale Lausteuille will get in the end picture for his lab. Here are what has happened, with some updates by Max Band or this Team.\n",
      "\n",
      "The new SJS BioFilasma Shootout & Crew experience will see collaboration between Oscar-nominated NASA scientist Gordon Boudreaux, highly placed panel member of the Physics and Astrophysics Underui Quape* and IRR physicist Dr. John D. Sayles offering days at each SETI Medical Career Appreciation Club – Day one. The main end goal for course made up by these three couples, who are pancreatic cancer-fighting cancer prevention researchers, String walked the walking stage with the silicon softball team leaders distributed across QPR Campus, delivering presentations, chanting the heralding of \"Interstellar Design\" of the Cancer Turnaround Producible Plasma plasma fasting corridor, a great mission catered by dual A.I.M. panelist Ramón Izquierdo. String also serves as interim leader of PARFA's Sunscan Radiometer Facility project to raise scientifically needed spending in US, like the Vanguard Information Cube at Virginia Tech in the nation's premier research center. He also oversaw the 12th Workshop over the Lunar CANDADAR collaborated with 12 others Nadia Krallroudo, Scruder Hayden, and Nathan Hraft, from technology expert Zhou Jing Le Hou and Esq., devoted to complete curating the location for intense observation space and outer space tugzals at our solar disc collisions, The WCF Composite Material Engine performed waves of story like those done for MISSION. Craig Emberton Chair in Atmospheric for NASA-funded NanoFIN Fish Industry Nanodevaganza at Caltech and the by-product of the California Deputy SRC Science Journalism Award experience Willi Saussle demonstrated teamwork in offering delib 0.19 percent of Space Police landing and field staging for making the first images of the Excelsior Quadrant.\n",
      "\n",
      "And do a proofread here and here:\n",
      "\n",
      "28 December 2016: D0120 hairline study presented at 58 Soggy for Valentine's Day 2014 talk at Physics Theory & Practice, a Nex. Kii-TeAK computing conference.\n",
      "\n",
      "Pieces\n",
      "\n",
      "David-Anne Hunt searches extraordinary new phenomena for repealing Identification (LED) and happily lovely Protectionarts Godoves\n",
      "\n",
      "Mr. JetSavary begins positron physics handing out letters in support of intervention on Ph/v game design games in her tiny sliver of Australia.\n",
      "\n",
      "My gift: Non-idiot graphene bandages for readers quealled by the impersonator called Aidyn Howard.\n",
      "\n",
      "Professor Lizzie Drake from School of Pharmacy at Weill Cornell Medical College becomes the first woman professor of medicine in Canada to be honoured with the Street Preferences grant from General Art Preparement School chanting Patterson and Whittaker flu****-inducing gases coined by seniors as great consolation for AM Bumper Storm Syndrome patients dying of heart failure.\n",
      "\n",
      "13 April 2017: Members of the NMIR Mystical Heat Monitor blog received an official pay change in exchange for a welcome letter given as a free marketing post at Layantha Izquierdo's College for U.S. Assistant Secretary of Health and Human Services. \"…suitable donators to help this content reach Culture-weary student mascbf lbs f industrial rew prisoners in classrooms and take each of your day off to honour your superiors. … [M]or a large article any she-male would love to publish, Living On Multiple Continents discuss more and more over the last few weeks. On the eve of corresponding it was first met with much's emoji-loved ol sketching mate Farage. Truly some BDSM sexsmith.\"\n",
      "\n",
      "Past used references at 15 in this new can't-miss excerpt from the title.\n",
      "\n",
      "July 2017: The Ontario Humanities Society (Ihs) is christened to formally support and encourage the redistribution of Canadian teaching around the world at the University of British Columbia.\n",
      "\n",
      "An alternate topical for Lester Handler's Newbury trademark engaging them https://t.co/3dX8J2rG3\n"
     ]
    }
   ],
   "source": [
    "sample_model(\n",
    "    model_name='117M',\n",
    "    seed=None,\n",
    "    nsamples=1,\n",
    "    batch_size=1,\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "    models_dir='models',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
